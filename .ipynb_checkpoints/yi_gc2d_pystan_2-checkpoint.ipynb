{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import numpy as np\n",
    "import pystan\n",
    "import scipy.io as sio\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 0: testing stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_d318d729a5f7d61c571fb4e13264ef98 NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.51999497413635\n",
      "(2000, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('y', array([  1.,  20.,   3.,   4.,  -1.,   3.]))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "model_code = \"\"\"\n",
    "   data {\n",
    "       int<lower=1> Nbins; // number of bins \n",
    "       vector[Nbins] x; // input\n",
    "       real<lower=0> sigma; // standard deviation for normal\n",
    "   }\n",
    "   transformed data {\n",
    "   }\n",
    "   parameters {\n",
    "       vector[Nbins] y; // output\n",
    "   }  \n",
    "   model {         \n",
    "        y ~ normal(x,sigma);\n",
    "   }\n",
    "\"\"\"\n",
    "\n",
    "datain = {'Nbins': 6,\n",
    "        'x': [1,20,3,4,-1,3],\n",
    "        'sigma': 2\n",
    "       }\n",
    "\n",
    "#sm = pystan.StanModel(model_code=model_code)\n",
    "fit = pystan.stan(model_code=model_code, data=datain,\n",
    "                  iter=1000, chains=4)\n",
    "\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)\n",
    "\n",
    "yextract = fit.extract('y')\n",
    "temp = yextract[\"y\"]\n",
    "print(temp.shape)\n",
    "op = sm.optimizing(data=datain)\n",
    "op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 1: linear-circular regression in 1d with von mises noise\n",
    "\n",
    "Our inputs are real values \n",
    "\n",
    "$$x_1,\\dots,x_N,$$ \n",
    "\n",
    "and our outputs are circular variables\n",
    "\n",
    "$$ y_1, \\dots, y_N. $$\n",
    "\n",
    "It's a bit of a hack (in the way that it's data-dependent), but for now we'll always assume that the output is shifted so that $y_1 = 0$ (need to understand if this actually changes the problem in any way? I don't think it should...)\n",
    "\n",
    "Our model parameters will be \n",
    "\n",
    "$$\\{\\alpha,\\beta\\},$$ \n",
    "\n",
    "with the model being \n",
    "\n",
    "$$\\left( y_i - \\text{mod}(\\alpha x_i, 2\\pi) \\right) \\sim \\text{von_mises}(0,\\beta) $$\n",
    "\n",
    "ie, $\\alpha$ is the \"slope,\" or frequency, and $\\beta$ is the variance of the noise distribution.\n",
    "\n",
    "I need to understand the following better in certain technical aspects, but:\n",
    "\n",
    "to actually implement this without the \"modulo,\" we do the following:\n",
    "\n",
    "1. first map $x$ to the unit vector $\\tilde{y} = (\\cos(\\alpha x),\\sin(\\alpha x))$\n",
    "2. then define the residual $r = m_{y}^{-1} \\tilde{y}$, where $m_{y}$ is the matrix representing rotation by $y$. \n",
    "3. now define $\\theta_r = \\text{acos}(r[1])$; then we simply require that $ r\\sim \\text{von_mises}(0,\\beta)$. Note that the $\\text{acos}$ throws away information about the residual as it never takes values between $-\\pi$ and $0$; however this is OK because of the symmetry of the v.m. dist. around $0$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "z = x.squeeze()\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nbins = 20\n",
    "x = 100*np.random.rand(Nbins,1)\n",
    "alpha = 40\n",
    "x = x - x.min()\n",
    "y = np.mod(2*np.pi*x/alpha,2*np.pi)\n",
    "y = np.column_stack((np.cos(y),np.sin(y)))\n",
    "mu_beta = 0\n",
    "sigma_beta = np.pi/4\n",
    "mu_alpha = 40\n",
    "sigma_alpha = 5\n",
    "x = x.transpose()\n",
    "x = x.squeeze()\n",
    "datain = {\n",
    "            'Nbins': Nbins,\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'mu_alpha': mu_alpha,\n",
    "            'sigma_alpha': sigma_alpha,\n",
    "            'mu_beta': mu_beta,\n",
    "            'sigma_beta': sigma_beta,            \n",
    "        }\n",
    "initin = {\n",
    "            'alpha': 40,\n",
    "            'beta': np.pi/8,\n",
    "        }\n",
    "initin = [initin]\n",
    "a = False\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_8f6c11d92978b2df8d492fce153fbc0d NOW.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "diagnostic_file not supported yet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-ab9552d2d652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#sm = pystan.StanModel(model_code=mcode)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#fit = sm.sampling(data=datain, chains=1, test_grad=True, init=initin, verbose=True,diagnostic_file=dstr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpystan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagnostic_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/samlewallen/miniconda3/lib/python3.5/site-packages/pystan/api.py\u001b[0m in \u001b[0;36mstan\u001b[0;34m(file, model_name, model_code, fit, data, pars, chains, iter, warmup, thin, init, seed, algorithm, control, sample_file, diagnostic_file, verbose, boost_lib, eigen_lib, n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                      \u001b[0msample_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagnostic_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiagnostic_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                      \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                      n_jobs=n_jobs, **kwargs)\n\u001b[0m\u001b[1;32m    396\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/samlewallen/miniconda3/lib/python3.5/site-packages/pystan/model.py\u001b[0m in \u001b[0;36msampling\u001b[0;34m(self, data, pars, chains, iter, warmup, thin, seed, init, sample_file, diagnostic_file, verbose, algorithm, control, n_jobs, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# del iter  # now builtins.iter is available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiagnostic_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"diagnostic_file not supported yet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: diagnostic_file not supported yet"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "mcode = \"\"\"\n",
    "    functions {\n",
    "        vector rotate_xy(vector x, vector y) {\n",
    "            // this function rotates vector y by -x (ie, minus the angle \n",
    "            // represented by x). for example, it gives [1;0] if x=y.         \n",
    "            \n",
    "            matrix[2, 2] m; // matrix representing rotation by -theta_x\n",
    "            m[1, 1] = x[1];\n",
    "            m[2, 1] = -x[2];\n",
    "            m[1, 2] = x[2];\n",
    "            m[2, 2] = x[1];        \n",
    "            return m*y;        \n",
    "        }        \n",
    "    }\n",
    "    data {\n",
    "       int<lower=0> Nbins; // number of bins \n",
    "       vector[Nbins] x; // input variables\n",
    "       unit_vector[2] y[Nbins]; // output variables \n",
    "       real<lower=0> mu_alpha;\n",
    "       real<lower=0> sigma_alpha;\n",
    "       real<lower=0> mu_beta;\n",
    "       real<lower=0> sigma_beta;                     \n",
    "    }\n",
    "    transformed data {\n",
    "        print(y);\n",
    "    }\n",
    "    parameters {\n",
    "        real<lower=0> alpha; // frequency\n",
    "        real<lower=0> beta; // variance\n",
    "    }\n",
    "    transformed parameters {\n",
    "        unit_vector[2] ytilde[Nbins];\n",
    "        unit_vector[2] temp;\n",
    "        real<lower = -1, upper = 1> temp2;\n",
    "        vector<lower = -pi(), upper = pi()>[Nbins] r;\n",
    "        \n",
    "        for (n in 1:Nbins) {\n",
    "            temp[1] = cos(2*pi()*x[n]/alpha);\n",
    "            temp[2] = sin(2*pi()*x[n]/alpha);\n",
    "            ytilde[n] = temp;\n",
    "            temp = rotate_xy(y[n],ytilde[n]);\n",
    "            temp2 = temp[1];\n",
    "            r[n] = acos(temp2);\n",
    "         }  \n",
    "         \n",
    "         print(alpha);\n",
    "         print(beta);\n",
    "         print(r);\n",
    "         print(y);\n",
    "         print(ytilde);\n",
    "    }          \n",
    "    model {    \n",
    "        alpha ~ normal(mu_alpha,sigma_alpha);\n",
    "        beta ~ normal(mu_beta,sigma_beta);\n",
    "        for (n in 1:Nbins) {\n",
    "            // r[n] ~ von_mises(0,beta);\n",
    "            r[n] ~ uniform(-beta,beta);\n",
    "        }\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "# sm = pystan.StanModel(model_code=model_code)\n",
    "# elapsed = time.time() - t\n",
    "# print(elapsed)\n",
    "# op = sm.optimizing(data=datain,init=initin,test_grad=True)\n",
    "\n",
    "dstr = '/Users/samlewallen/Desktop/dfile'\n",
    "#sm = pystan.StanModel(model_code=mcode)\n",
    "#fit = sm.sampling(data=datain, chains=1, test_grad=True, init=initin, verbose=True,diagnostic_file=dstr)\n",
    "fit = pystan.stan(model_code=mcode, data=datain, chains=1, init=initin, test_grad=True, diagnostic_file=dstr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pystan.model.StanModel at 0x10e0a30f0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 2: constant hexagonal lattice\n",
    "\n",
    "- parameters are p (spacing) and theta (rotation) (both constant across brain)\n",
    "- options for noise model:\n",
    "    - von mises distribution with fixed variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.transpose>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from matlab\n",
    "str = '/Users/samlewallen/Documents/neuroscience/BRAIN_data_project/Nbins.mat'\n",
    "mat_contents = sio.loadmat(str)\n",
    "Nbins = mat_contents['Nbins']\n",
    "str = '/Users/samlewallen/Documents/neuroscience/BRAIN_data_project/x.mat'\n",
    "mat_contents = sio.loadmat(str)\n",
    "x = mat_contents['x']\n",
    "str = '/Users/samlewallen/Documents/neuroscience/BRAIN_data_project/y.mat'\n",
    "mat_contents = sio.loadmat(str)\n",
    "y = mat_contents['y']\n",
    "x = np.float64(x)\n",
    "y = np.float64(y)\n",
    "Nbins = np.int(Nbins)\n",
    "x = x.transpose()\n",
    "y = y.transpose()\n",
    "x = x.squeeze()\n",
    "y = y.squeeze()\n",
    "\n",
    "x.transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_5d1ec03d0e40de3dc4d5c71af6f4d73a NOW.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.511999130249023\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "ocode = \"\"\"\n",
    "   data {\n",
    "       int<lower=1> Nbins; // number of bins \n",
    "       vector[Nbins] x; // position bins \n",
    "       vector[Nbins] y; // data \n",
    "   }\n",
    "   transformed data {\n",
    "       int<lower=1> Nbumps; // number of bumps to consider % for now, hard-coded   \n",
    "        real<lower=0> sigmaSqGP;\n",
    "        real<lower=0> etaSqGP;\n",
    "        real<lower=0> rhoSqGP;\n",
    "        Nbumps = 5; \n",
    "        sigmaSqGP = .01;\n",
    "        etaSqGP = .01;\n",
    "        rhoSqGP = 1;\n",
    "   }\n",
    "   parameters {\n",
    "       simplex[Nbumps] lambda; // scaled \"bump domains\" \n",
    "       vector<lower=0>[Nbumps] bumpSigma; // bump widths \n",
    "       vector<lower=0>[Nbumps] bumpHeight; // bump heights\n",
    "       // real<lower=0> sigmaSqGP; \n",
    "       // real<lower=0> etaSqGP; \n",
    "       // real<lower=0> rhoSqGP; \n",
    "   }  \n",
    "   transformed parameters {\n",
    "       vector<lower=x[1],upper=x[Nbins]>[Nbumps] bumpCtrs; // bump centers \n",
    "       vector<lower=x[1],upper=x[Nbins]>[Nbumps] bumpDomainLengths; \n",
    "       bumpDomainLengths = (x[Nbins] - x[1])*lambda;  \n",
    "       bumpCtrs[1] = .5*bumpDomainLengths[1];    \n",
    "       for (n in 2:Nbumps)\n",
    "         bumpCtrs[n] = bumpCtrs[n-1] + .5*bumpDomainLengths[n-1] + .5*bumpDomainLengths[n]; \n",
    "   }\n",
    "   model {         \n",
    "       vector[Nbins] mu; \n",
    "       matrix[Nbins,Nbins] Sigma; \n",
    "       vector[Nbumps] alpha; \n",
    "       for (i in 1:Nbumps) \n",
    "         alpha[i] = 3;\n",
    "   \n",
    "      // compute GP mean mu: \n",
    "       mu = 0*y;   \n",
    "       for (n in 1:Nbumps)\n",
    "         mu = mu + bumpHeight[n] * exp( -( x-bumpCtrs[n]).*(x-bumpCtrs[n] ) / (2*bumpSigma[n]^2) ); \n",
    "   \n",
    "      // compute GP cov Sigma:    \n",
    "      // off-diagonal elements \n",
    "       for (i in 1:(Nbins-1)) { \n",
    "         for (j in (i+1):Nbins) { \n",
    "           Sigma[i, j] = etaSqGP * exp(-rhoSqGP * pow(x[i] - x[j],2)); \n",
    "           Sigma[j, i] = Sigma[i, j]; \n",
    "          } \n",
    "       } \n",
    "      // diagonal elements \n",
    "       for (k in 1:Nbins)  \n",
    "           Sigma[k, k] = etaSqGP + sigmaSqGP;  // + jitter \n",
    "   \n",
    "      // models and priors: \n",
    "       lambda ~ dirichlet(alpha); \n",
    "       for (i in 1:Nbumps) \n",
    "           bumpSigma[i] ~ normal(8,3); \n",
    "       for (i in 1:Nbumps) \n",
    "           bumpHeight[i] ~ normal(1,.3); \n",
    "       // etaSqGP ~ cauchy(0, .1); \n",
    "       // rhoSqGP ~ cauchy(0, 1); \n",
    "       // sigmaSqGP ~ cauchy(0, .1); \n",
    "   \n",
    "      // process: \n",
    "       y ~ multi_normal(mu, Sigma); \n",
    "   }\n",
    "\"\"\"\n",
    "sm = pystan.StanModel(model_code=ocode)\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datain = {'x': x,\n",
    "        'y': y,\n",
    "        'Nbins': Nbins\n",
    "       }\n",
    "op = sm.optimizing(data=datain)\n",
    "str = '/Users/samlewallen/Documents/neuroscience/BRAIN_data_project/map.mat'\n",
    "sio.savemat(str,op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.807563066482544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_5d1ec03d0e40de3dc4d5c71af6f4d73a.\n",
       "2 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=2000.\n",
       "\n",
       "                       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "lambda[0]              0.26    0.15   0.15   0.06   0.11   0.28   0.41   0.42      1   9.98\n",
       "lambda[1]              0.24    0.05   0.05   0.13   0.19   0.26   0.27    0.3      1   1.57\n",
       "lambda[2]              0.29    0.19   0.19   0.06    0.1   0.26   0.48   0.55      1   6.35\n",
       "lambda[3]              0.13  4.9e-3   0.04   0.05   0.11   0.13   0.15    0.2     60   1.04\n",
       "lambda[4]               0.1  2.5e-3   0.02   0.06   0.09    0.1   0.11   0.14     70   1.03\n",
       "bumpSigma[0]           6.96    3.84   3.84   0.51   2.82   8.07   9.97  13.32      1   1.63\n",
       "bumpSigma[1]          11.09    1.44   2.04   7.27   9.55  11.16  12.53  14.98      2   1.35\n",
       "bumpSigma[2]           7.47    5.55   5.55   0.16   1.48   9.88  12.58  15.17      1   2.97\n",
       "bumpSigma[3]           6.74    0.13    2.8    1.9   4.52   6.76    8.6  12.41    429   1.01\n",
       "bumpSigma[4]           3.57    0.21   3.01   0.09   1.41    2.5   5.47  11.06    199   1.03\n",
       "bumpHeight[0]          0.79    0.17    0.3   0.16   0.63   0.87   0.99   1.28      3   1.16\n",
       "bumpHeight[1]          1.04    0.11   0.16   0.74   0.92   1.04   1.16   1.33      2   1.51\n",
       "bumpHeight[2]          0.97    0.19   0.33   0.12   0.87   1.07   1.18   1.41      3   1.19\n",
       "bumpHeight[3]          0.51    0.01   0.25   0.18   0.36   0.46    0.6   1.23    399    1.0\n",
       "bumpHeight[4]          0.67    0.02    0.4    0.1   0.32   0.63   0.99   1.45    275   1.02\n",
       "bumpCtrs[0]           62.61   37.29  37.29  14.71  25.89  67.44  99.62 102.26      1   9.98\n",
       "bumpCtrs[1]          182.86   82.85  82.85  97.26 100.03 182.38  265.7 268.08      1   60.5\n",
       "bumpCtrs[2]          310.62   45.35  45.35 262.84 265.46 305.71 355.17 365.26      1  15.36\n",
       "bumpCtrs[3]           411.7    0.28    4.1 404.46  408.7 412.04 414.55 419.66    212    1.0\n",
       "bumpCtrs[4]          466.33    0.61   5.09 454.95 464.16 466.11  469.1 475.61     70   1.03\n",
       "bumpDomainLengths[0] 125.21   74.59  74.59  29.42  51.78 134.89 199.24 204.51      1   9.98\n",
       "bumpDomainLengths[1] 115.29   24.35  24.35  62.97  95.52 126.13 134.66 145.88      1   1.57\n",
       "bumpDomainLengths[2] 140.25   94.36  94.36  31.61  47.34 126.87  235.6 267.74      1   6.35\n",
       "bumpDomainLengths[3]  61.92     2.4  18.59  22.44  52.15  61.91  73.02  99.08     60   1.04\n",
       "bumpDomainLengths[4]  47.34    1.22  10.19  28.79  41.79  47.78  51.68   70.1     70   1.03\n",
       "lp__                  70.52    0.31   3.31  63.38  68.32  70.87  72.87  76.12    111   1.02\n",
       "\n",
       "Samples were drawn using NUTS at Wed Dec 28 04:29:40 2016.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "fit = sm.sampling(data=datain,iter=2000, chains=2)\n",
    "elapsed = time.time() - t\n",
    "str = '/Users/samlewallen/Documents/neuroscience/BRAIN_data_project/fit.mat'\n",
    "sio.savemat(str,fit.extract())\n",
    "print(elapsed)\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bumpHeight',\n",
       "              array([[ 0.93003183,  1.06907211,  1.33177389,  0.33392324,  0.31640749],\n",
       "                     [ 0.93785883,  1.20738098,  0.67972548,  0.61116771,  0.76595339],\n",
       "                     [ 0.80772965,  1.10899196,  0.8953727 ,  0.40598797,  1.38987105],\n",
       "                     ..., \n",
       "                     [ 1.49481265,  0.81634302,  1.05731252,  0.30569385,  0.54227119],\n",
       "                     [ 1.4696026 ,  0.80443629,  1.22259213,  0.45043697,  0.86776437],\n",
       "                     [ 0.85852891,  0.7521639 ,  1.06925778,  0.17787774,  1.07541832]]))])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit.extract('bumpHeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_708d9d0d02e5020b135942ec27793dbf.\n",
       "1 chains, each with iter=1000; warmup=500; thin=1; \n",
       "post-warmup draws per chain=500, total post-warmup draws=500.\n",
       "\n",
       "                       mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "lambda[0]              0.05  2.2e-3   0.01   0.03   0.05   0.06   0.06   0.07     25   1.03\n",
       "lambda[1]              0.03  2.4e-3   0.01   0.01   0.02   0.03   0.04   0.07     27   1.05\n",
       "lambda[2]              0.91  4.7e-4 5.3e-3    0.9   0.91   0.91   0.92   0.92    130   1.02\n",
       "bumpSigma[0]           2.51    0.41   2.52   0.35   1.06    1.7   2.53  10.35     38   1.01\n",
       "bumpSigma[1]           3.95    0.75   3.51   0.03   1.34   2.79   5.91  12.66     22   1.11\n",
       "bumpSigma[2]          12.62    0.16   1.57   9.57  11.41  12.57  13.82  15.69     96   1.02\n",
       "bumpHeight[0]           0.8    0.05   0.39   0.14   0.49   0.84    1.1   1.47     55   1.01\n",
       "bumpHeight[1]          0.73    0.06   0.38   0.17   0.38   0.75   1.02   1.44     35   1.07\n",
       "bumpHeight[2]          1.14  7.4e-3   0.11   0.93   1.06   1.14   1.21   1.35    233   1.01\n",
       "bumpCtrs[0]           13.35    0.53   2.67   6.37  12.64  13.87   14.9   17.2     25   1.03\n",
       "bumpCtrs[1]           34.51    0.48   2.83  27.02  33.57  34.73  35.95  39.79     35   1.01\n",
       "bumpCtrs[2]          266.16    0.11    1.3 263.72  265.3 266.05 267.04 268.61    130   1.02\n",
       "bumpDomainLengths[0]  26.71    1.07   5.34  12.73  25.28  27.75  29.81  34.39     25   1.03\n",
       "bumpDomainLengths[1]  15.61     1.2   6.22   7.06  11.47  14.46  17.65  32.93     27   1.05\n",
       "bumpDomainLengths[2] 447.68    0.23    2.6 442.78 445.92 447.89  449.4 452.56    130   1.02\n",
       "lp__                   26.5    0.61   2.86  19.81  24.87  26.84  28.73  30.71     22   1.06\n",
       "\n",
       "Samples were drawn using NUTS at Wed Dec 28 04:16:11 2016.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
